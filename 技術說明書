ğŸ—‚ï¸ å°ˆæ¡ˆæª”æ¡ˆçµæ§‹
text
web-search-scorer/
â”œâ”€â”€ ContentScorer.py        # æ ¸å¿ƒæœå°‹èˆ‡è©•åˆ†é‚è¼¯
â”œâ”€â”€ app.py                  # Streamlit ç¶²é æ‡‰ç”¨ä¸»ç¨‹å¼
â”œâ”€â”€ requirements.txt        # Python å¥—ä»¶ä¾è³´æ¸…å–®
â””â”€â”€ .gitignore             # Git å¿½ç•¥æª”æ¡ˆè¨­å®š
ğŸ“¦ æ ¸å¿ƒé¡åˆ¥ï¼šWebContentScorerï¼ˆContentScorer.pyï¼‰
é¡åˆ¥çµæ§‹æ¦‚è¦½
python
class WebContentScorer:
    """ç¶²è·¯å…§å®¹æœå°‹èˆ‡è©•åˆ†ç³»çµ±æ ¸å¿ƒé¡åˆ¥"""
    
    def __init__(self, serpapi_key=None)
    # åˆå§‹åŒ–æ–¹æ³•
    
    # === æœå°‹ç›¸é—œæ–¹æ³• ===
    def search_google_serpapi(keyword, num_results)
    def search_duckduckgo(keyword, num_results)
    
    # === å…§å®¹æŠ“å–æ–¹æ³• ===
    def extract_content_advanced(url)
    
    # === è©•åˆ†è¨ˆç®—æ–¹æ³• ===
    def calculate_relevance_score(keyword, content, title, snippet)
    def calculate_quality_score(content, url, title, publish_date)
    def calculate_final_score(relevance, quality)
    
    # === ä¸»è¦åŸ·è¡Œæ–¹æ³• ===
    def run(keyword, num_results)
    def export_results(df, filename)
ğŸ” è©³ç´°å‡½æ•¸èªªæ˜
1. åˆå§‹åŒ–æ–¹æ³• __init__()
åŠŸèƒ½ï¼šå»ºç«‹æœå°‹å™¨å¯¦ä¾‹ï¼Œè¨­å®šåŸºæœ¬åƒæ•¸

åƒæ•¸ï¼š

serpapi_keyï¼šSerpAPI å¯†é‘°ï¼ˆå¯é¸ï¼‰

åˆå§‹åŒ–å…§å®¹ï¼š

è¨­å®š HTTP è«‹æ±‚æ¨™é ­

å®šç¾©é»‘åå–®ç¶²åŸŸï¼ˆç¶­åŸºç™¾ç§‘ç­‰ï¼‰

åˆå§‹åŒ–çµæœåˆ—è¡¨

python
self.blacklist_domains = [
    'wikipedia.org',
    'wiki',
    'baike.baidu.com',
    'ç¶­åŸºç™¾ç§‘',
    'wikimedia'
]
2. æœå°‹æ–¹æ³•
2.1 search_google_serpapi(keyword, num_results)
åŠŸèƒ½ï¼šä½¿ç”¨ SerpAPI æœå°‹ Google

æµç¨‹ï¼š

æª¢æŸ¥æ˜¯å¦æœ‰ API å¯†é‘°

ç™¼é€ API è«‹æ±‚

è§£ææœå°‹çµæœ

éæ¿¾é»‘åå–®ç¶²ç«™

è¿”å›çµæœåˆ—è¡¨

è¼¸å…¥ï¼š

keywordï¼šæœå°‹é—œéµè©

num_resultsï¼šéœ€è¦çš„çµæœæ•¸é‡

è¼¸å‡ºï¼š

python
[
    {
        "title": "æ–‡ç« æ¨™é¡Œ",
        "url": "ç¶²å€",
        "snippet": "æ‘˜è¦",
        "source": "ä¾†æºç¶²åŸŸ"
    },
    ...
]
2.2 search_duckduckgo(keyword, num_results)
åŠŸèƒ½ï¼šä½¿ç”¨ DuckDuckGo å…è²»æœå°‹ï¼ˆå‚™ç”¨æ–¹æ¡ˆï¼‰

ç‰¹é»ï¼š

ç„¡éœ€ API å¯†é‘°

åŒæ¨£éæ¿¾é»‘åå–®

çµæ§‹èˆ‡ SerpAPI ç›¸åŒ

3. å…§å®¹æŠ“å–æ–¹æ³•
extract_content_advanced(url)
åŠŸèƒ½ï¼šå¾ç¶²é æŠ“å–ä¸¦è§£æä¸»è¦å…§å®¹

æŠ“å–æµç¨‹ï¼š

ç™¼é€ HTTP è«‹æ±‚

ä½¿ç”¨ BeautifulSoup è§£æ HTML

æå–æ¨™é¡Œï¼ˆå¤šç¨®å€™é¸æ–¹æ¡ˆï¼‰

ç§»é™¤ç„¡ç”¨æ¨™ç±¤ï¼ˆscript, style, nav...ï¼‰

å®šä½ä¸»è¦å…§å®¹å€åŸŸ

æå–æœ‰æ•ˆæ®µè½

æ¸…ç†æ–‡å­—æ ¼å¼

æå–ç™¼å¸ƒæ—¥æœŸ

è¿”å›è³‡æ–™çµæ§‹ï¼š

python
{
    "content": "æ–‡ç« æ­£æ–‡å…§å®¹",
    "title": "æ–‡ç« æ¨™é¡Œ",
    "publish_date": "ç™¼å¸ƒæ—¥æœŸ",
    "method": "æŠ“å–æ–¹æ³•",
    "success": True/False,
    "error": "éŒ¯èª¤è¨Šæ¯ï¼ˆè‹¥å¤±æ•—ï¼‰"
}
å…§å®¹é¸æ“‡å™¨å„ªå…ˆé †åºï¼š

python
content_selectors = [
    'article',              # HTML5 èªç¾©æ¨™ç±¤
    '[role="main"]',        # ARIA æ¨™è¨˜
    '.article-content',     # å¸¸è¦‹é¡åˆ¥å
    '.post-content',
    '.entry-content',
    '.content',
    'main',
    '#content',
    '#main'
]
4. è©•åˆ†è¨ˆç®—æ–¹æ³•
4.1 calculate_relevance_score(keyword, content, title, snippet)
åŠŸèƒ½ï¼šè¨ˆç®—å…§å®¹èˆ‡é—œéµè©çš„ç›¸é—œæ€§ï¼ˆ0-100åˆ†ï¼‰

è©•åˆ†é …ç›®ï¼š

é …ç›®	åˆ†æ•¸	è¨ˆç®—æ–¹å¼
TF-IDF èªç¾©ç›¸ä¼¼åº¦	40åˆ†	ä½¿ç”¨ scikit-learn è¨ˆç®—é¤˜å¼¦ç›¸ä¼¼åº¦ Ã— 40
æ¨™é¡Œå®Œå…¨åŒ¹é…	25åˆ†	é—œéµè©å®Œæ•´å‡ºç¾åœ¨æ¨™é¡Œä¸­
æ¨™é¡Œéƒ¨åˆ†åŒ¹é…	15åˆ†	é—œéµè©éƒ¨åˆ†å‡ºç¾åœ¨æ¨™é¡Œä¸­
é—œéµè©é »ç‡	æœ€å¤š20åˆ†	æ­£æ–‡å‡ºç¾æ¬¡æ•¸ Ã— 2ï¼Œä¸Šé™20
é—œéµè©ä½ç½®	æœ€å¤š15åˆ†	å‰500å­—:+15, å‰1000å­—:+10, å‰2000å­—:+5
æ¼”ç®—æ³•ç´°ç¯€ï¼š

python
# æ¨™é¡ŒåŠ æ¬Šï¼ˆæé«˜æ¨™é¡Œé‡è¦æ€§ï¼‰
weighted_content = f"{title} {title} {title} {snippet} {content}"

# TF-IDF å‘é‡åŒ–
vectorizer = TfidfVectorizer(token_pattern=r'(?u)\b\w+\b')
tfidf_matrix = vectorizer.fit_transform([keyword, weighted_content])
similarity = cosine_similarity(tfidf_matrix[0:1], tfidf_matrix[1:2])[0][0]
base_score = similarity * 40
4.2 calculate_quality_score(content, url, title, publish_date)
åŠŸèƒ½ï¼šè©•ä¼°å…§å®¹å“è³ªï¼ˆ0-100åˆ†ï¼‰

è©•åˆ†é …ç›®ï¼š

é¡åˆ¥	åˆ†æ•¸	è©•åˆ†ç´°ç¯€
å…§å®¹æ·±åº¦	30åˆ†	é•·åº¦15åˆ† + çµæ§‹15åˆ†
å…§å®¹è±å¯Œåº¦	25åˆ†	æ•¸å­—8åˆ† + å¼•ç”¨7åˆ† + æ¨™é»10åˆ†
ç¶²ç«™ä¿¡ä»»åº¦	20åˆ†	æ–°è15åˆ†/å°ˆæ¥­12åˆ†/HTTPS 8åˆ†
æ™‚æ•ˆæ€§	15åˆ†	è¶Šæ–°è¶Šé«˜åˆ†ï¼ˆé€±å…§15åˆ†â†’å¹´å…§3åˆ†ï¼‰
å¯è®€æ€§	10åˆ†	æ¨™é¡Œ5åˆ† + ç„¡åƒåœ¾å…§å®¹5åˆ†
ç¶²ç«™é¡å‹åˆ†ç´šï¼š

python
# æ–°èåª’é«”ï¼ˆ15åˆ†ï¼‰
news_domains = ['news', 'bbc', 'cnn', 'nytimes', 'reuters', 
                'bloomberg', 'guardian', 'forbes', 'techcrunch']

# å°ˆæ¥­ç¶²ç«™ï¼ˆ12åˆ†ï¼‰
professional_domains = ['.gov', '.edu', '.org', 'medium', 
                       'github', 'stackoverflow', 'scholar']

# HTTPS ç¶²ç«™ï¼ˆ8åˆ†ï¼‰
trusted_domains = ['https://']
æ™‚æ•ˆæ€§è¨ˆç®—ï¼š

python
if days_ago <= 7:    score += 15  # ä¸€é€±å…§
elif days_ago <= 30:  score += 12  # ä¸€å€‹æœˆå…§
elif days_ago <= 90:  score += 9   # ä¸‰å€‹æœˆå…§
elif days_ago <= 180: score += 6   # åŠå¹´å…§
elif days_ago <= 365: score += 3   # ä¸€å¹´å…§
4.3 calculate_final_score(relevance, quality)
åŠŸèƒ½ï¼šè¨ˆç®—æœ€çµ‚ç¶œåˆè©•åˆ†

å…¬å¼ï¼š

python
ç¶œåˆè©•åˆ† = (ç›¸é—œæ€§è©•åˆ† Ã— 0.60) + (å“è³ªè©•åˆ† Ã— 0.40)
æ¬Šé‡ç†ç”±ï¼š

ç›¸é—œæ€§ 60%ï¼šæ‰¾åˆ°å°çš„å…§å®¹æœ€é‡è¦

å“è³ª 40%ï¼šç¢ºä¿å…§å®¹æœ‰åƒ¹å€¼

5. ä¸»è¦åŸ·è¡Œæ–¹æ³•
5.1 run(keyword, num_results)
åŠŸèƒ½ï¼šåŸ·è¡Œå®Œæ•´çš„æœå°‹â†’æŠ“å–â†’è©•åˆ†æµç¨‹

åŸ·è¡Œæ­¥é©Ÿï¼š

text
æ­¥é©Ÿ 1ï¼šæœå°‹ï¼ˆ20%é€²åº¦ï¼‰
    â†“
æœå°‹ Google/DuckDuckGo
éæ¿¾é»‘åå–®ç¶²ç«™
    â†“
æ­¥é©Ÿ 2ï¼šæŠ“å–å…§å®¹ï¼ˆ20-90%é€²åº¦ï¼‰
    â†“
for æ¯å€‹æœå°‹çµæœ:
    - æŠ“å–ç¶²é å…§å®¹
    - è¨ˆç®—ç›¸é—œæ€§è©•åˆ†
    - è¨ˆç®—å“è³ªè©•åˆ†
    - è¨ˆç®—ç¶œåˆè©•åˆ†
    - å„²å­˜çµæœ
    â†“
æ­¥é©Ÿ 3ï¼šæ’åºè¼¸å‡ºï¼ˆ90-100%é€²åº¦ï¼‰
    â†“
æŒ‰ç¶œåˆè©•åˆ†æ’åº
ç”Ÿæˆ DataFrame
é¡¯ç¤ºçµ±è¨ˆè³‡è¨Š
è¿”å›è³‡æ–™ï¼š

python
pandas.DataFrame({
    'æ’å': [1, 2, 3, ...],
    'æ ‡é¢˜': ['...', '...', ...],
    'æ¥æº': ['...', '...', ...],
    'ç½‘å€': ['...', '...', ...],
    'ç›¸å…³æ€§è¯„åˆ†': [85.5, 82.3, ...],
    'å“è´¨è¯„åˆ†': [78.2, 75.1, ...],
    'ç»¼åˆè¯„åˆ†': [82.5, 79.3, ...],
    'å†…å®¹é•¿åº¦': [3500, 2800, ...],
    'å‘å¸ƒæ—¥æœŸ': ['2025-10-15', ...],
    'æ‘˜è¦': ['...', '...', ...],
    'æŠ“å–çŠ¶æ€': ['æˆåŠŸ', 'æˆåŠŸ', ...]
})
5.2 export_results(df, filename)
åŠŸèƒ½ï¼šåŒ¯å‡ºçµæœåˆ°æª”æ¡ˆ

æ”¯æ´æ ¼å¼ï¼š

Excel (.xlsx) - å„ªå…ˆ

CSV (.csv) - å‚™ç”¨

ğŸ–¥ï¸ Streamlit æ‡‰ç”¨ç¨‹å¼ï¼ˆapp.pyï¼‰
æ‡‰ç”¨çµæ§‹
text
Streamlit App
â”œâ”€â”€ é é¢é…ç½®
â”œâ”€â”€ è‡ªè¨‚ CSS æ¨£å¼
â”œâ”€â”€ Session State ç®¡ç†
â”œâ”€â”€ å´é‚Šæ¬„ï¼ˆé…ç½®å€ï¼‰
â”‚   â”œâ”€â”€ SerpAPI è¨­å®š
â”‚   â”œâ”€â”€ æœå°‹åƒæ•¸
â”‚   â”œâ”€â”€ è©•åˆ†æ¬Šé‡èª¿æ•´
â”‚   â””â”€â”€ æœå°‹æ­·å²
â”œâ”€â”€ ä¸»é é¢
â”‚   â”œâ”€â”€ æ¨™é¡Œèˆ‡èªªæ˜
â”‚   â”œâ”€â”€ æœå°‹è¼¸å…¥æ¡†
â”‚   â”œâ”€â”€ å¿«é€Ÿæœå°‹æŒ‰éˆ•
â”‚   â””â”€â”€ æœå°‹åŸ·è¡Œé‚è¼¯
â””â”€â”€ çµæœå±•ç¤ºå€
    â”œâ”€â”€ çµ±è¨ˆå¡ç‰‡
    â”œâ”€â”€ è¦–è¦ºåŒ–åœ–è¡¨ï¼ˆ3å€‹Tabï¼‰
    â”œâ”€â”€ TOP 3 è©³ç´°å±•ç¤º
    â””â”€â”€ åŒ¯å‡ºåŠŸèƒ½
ä¸»è¦åŠŸèƒ½æ¨¡çµ„
1. Session State ç®¡ç†
python
st.session_state.results_df      # æœå°‹çµæœ DataFrame
st.session_state.search_history  # æœå°‹æ­·å²åˆ—è¡¨
st.session_state.quick_search    # å¿«é€Ÿæœå°‹è§¸ç™¼
2. å´é‚Šæ¬„é…ç½®
SerpAPI é…ç½®ï¼šAPI å¯†é‘°è¼¸å…¥

æœå°‹åƒæ•¸ï¼šçµæœæ•¸é‡æ»‘æ¡¿ï¼ˆ5-20æ¢ï¼‰

è©•åˆ†æ¬Šé‡ï¼šç›¸é—œæ€§/å“è³ªæ¯”ä¾‹èª¿æ•´

æœå°‹æ­·å²ï¼šæœ€è¿‘5æ¬¡æœå°‹è¨˜éŒ„

3. æœå°‹ä»‹é¢
ä¸­å¤®å¤§å‹è¼¸å…¥æ¡†

5å€‹å¿«é€Ÿæœå°‹æŒ‰éˆ•ï¼ˆäººå·¥æ™ºæ…§ã€æ°£å€™è®Šé·ç­‰ï¼‰

å³æ™‚æœå°‹ç‹€æ…‹é¡¯ç¤º

4. çµæœå±•ç¤º
çµ±è¨ˆå¡ç‰‡ï¼ˆ4å€‹ï¼‰ï¼š

ç¸½çµæœæ•¸

å¹³å‡è©•åˆ†

æˆåŠŸæŠ“å–æ•¸

æœ€é«˜åˆ†

è¦–è¦ºåŒ–åœ–è¡¨ï¼ˆ3å€‹Tabï¼‰ï¼š

Tab 1 - è©•åˆ†åˆ†ä½ˆ

python
- æŸ±ç‹€åœ–ï¼šæ’å vs ç¶œåˆè©•åˆ†
- çµ±è¨ˆè¡¨æ ¼ï¼šå¹³å‡/æœ€é«˜/æœ€ä½/ä¸­ä½æ•¸/æ¨™æº–å·®
- é¤…åœ–ï¼šè©•åˆ†ç­‰ç´šåˆ†ä½ˆï¼ˆå„ªç§€/è‰¯å¥½/ä¸€èˆ¬/è¼ƒä½ï¼‰
Tab 2 - ç›¸é—œæ€§ vs å“è³ª

python
- æ•£é»åœ–ï¼šXè»¸=ç›¸é—œæ€§ï¼ŒYè»¸=å“è³ªï¼Œæ°£æ³¡å¤§å°=ç¶œåˆè©•åˆ†
- ç›¸é—œä¿‚æ•¸åˆ†æ
Tab 3 - è³‡æ–™è¡¨æ ¼

python
- ç¯©é¸å™¨ï¼šæœ€ä½è©•åˆ†ã€æŠ“å–ç‹€æ…‹ã€æ’åºæ–¹å¼
- å®Œæ•´è³‡æ–™è¡¨æ ¼
TOP 3 è©³ç´°å±•ç¤ºï¼š

å¯å±•é–‹å¡ç‰‡

é›·é”åœ–ï¼ˆç›¸é—œæ€§ vs å“è³ªï¼‰

å®Œæ•´è³‡è¨Šé¡¯ç¤º

åŒ¯å‡ºåŠŸèƒ½ï¼š

Excel æ ¼å¼

CSV æ ¼å¼

JSON æ ¼å¼

ğŸ”§ æŠ€è¡“æ£§
æ ¸å¿ƒå¥—ä»¶
å¥—ä»¶	ç‰ˆæœ¬	ç”¨é€”
streamlit	â‰¥1.31.0	ç¶²é æ‡‰ç”¨æ¡†æ¶
requests	â‰¥2.31.0	HTTP è«‹æ±‚
beautifulsoup4	â‰¥4.12.0	HTML è§£æ
pandas	â‰¥2.0.0	è³‡æ–™è™•ç†
scikit-learn	â‰¥1.3.0	TF-IDF è¨ˆç®—
plotly	â‰¥5.18.0	äº’å‹•å¼åœ–è¡¨
openpyxl	â‰¥3.1.0	Excel åŒ¯å‡º
lxml	â‰¥4.9.0	XML è§£æ
ğŸ“Š è³‡æ–™æµç¨‹åœ–
text
ç”¨æˆ¶è¼¸å…¥é—œéµè©
    â†“
WebContentScorer.run()
    â†“
â”œâ”€ æœå°‹éšæ®µ
â”‚  â””â”€ search_google_serpapi() / search_duckduckgo()
â”‚      â””â”€ éæ¿¾é»‘åå–®
â”‚          â””â”€ è¿”å›æœå°‹çµæœåˆ—è¡¨
â”‚
â”œâ”€ æŠ“å–éšæ®µ
â”‚  â””â”€ for æ¯å€‹ URL:
â”‚      â””â”€ extract_content_advanced()
â”‚          â”œâ”€ æŠ“å– HTML
â”‚          â”œâ”€ è§£æå…§å®¹
â”‚          â””â”€ æå–æ¨™é¡Œ/æ­£æ–‡/æ—¥æœŸ
â”‚
â”œâ”€ è©•åˆ†éšæ®µ
â”‚  â””â”€ for æ¯å€‹å…§å®¹:
â”‚      â”œâ”€ calculate_relevance_score()  â†’ ç›¸é—œæ€§è©•åˆ†
â”‚      â”œâ”€ calculate_quality_score()     â†’ å“è³ªè©•åˆ†
â”‚      â””â”€ calculate_final_score()       â†’ ç¶œåˆè©•åˆ†
â”‚
â””â”€ çµæœéšæ®µ
   â”œâ”€ æŒ‰ç¶œåˆè©•åˆ†æ’åº
   â”œâ”€ ç”Ÿæˆ DataFrame
   â””â”€ è¿”å›çµ¦ Streamlit
       â†“
   Streamlit é¡¯ç¤º
   â”œâ”€ çµ±è¨ˆå¡ç‰‡
   â”œâ”€ è¦–è¦ºåŒ–åœ–è¡¨
   â”œâ”€ TOP 3 å±•ç¤º
   â””â”€ åŒ¯å‡ºåŠŸèƒ½
ğŸ¯ æ ¸å¿ƒæ¼”ç®—æ³•ç¸½çµ
ç›¸é—œæ€§æ¼”ç®—æ³•
text
1. TF-IDF å‘é‡åŒ–
2. é¤˜å¼¦ç›¸ä¼¼åº¦è¨ˆç®—
3. æ¨™é¡ŒåŒ¹é…åŠ æ¬Š
4. é »ç‡åŠ åˆ†
5. ä½ç½®åŠ åˆ†
â†’ ç¸½åˆ† 0-100
å“è³ªæ¼”ç®—æ³•
text
1. å…§å®¹æ·±åº¦ï¼ˆé•·åº¦+çµæ§‹ï¼‰
2. è±å¯Œåº¦ï¼ˆæ•¸å­—+å¼•ç”¨+æ¨™é»ï¼‰
3. ç¶²ç«™é¡å‹åˆ†ç´š
4. æ™‚æ•ˆæ€§è¡°æ¸›
5. å¯è®€æ€§æª¢æŸ¥
â†’ ç¸½åˆ† 0-100
ç¶œåˆè©•åˆ†
text
ç›¸é—œæ€§ Ã— 60% + å“è³ª Ã— 40% = ç¶œåˆè©•åˆ†ï¼ˆ0-100ï¼‰
ğŸš€ ä½¿ç”¨æµç¨‹
text
1. å•Ÿå‹• Streamlit æ‡‰ç”¨
   â””â”€ streamlit run app.py

2. è¼¸å…¥æœå°‹é—œéµè©
   â””â”€ æˆ–é»æ“Šå¿«é€Ÿæœå°‹æŒ‰éˆ•

3. èª¿æ•´åƒæ•¸ï¼ˆå¯é¸ï¼‰
   â”œâ”€ çµæœæ•¸é‡
   â”œâ”€ è©•åˆ†æ¬Šé‡
   â””â”€ API å¯†é‘°

4. é–‹å§‹æœå°‹
   â””â”€ å³æ™‚é¡¯ç¤ºé€²åº¦

5. æŸ¥çœ‹çµæœ
   â”œâ”€ çµ±è¨ˆæ¦‚è¦½
   â”œâ”€ è¦–è¦ºåŒ–åˆ†æ
   â””â”€ TOP 3 è©³æƒ…

6. åŒ¯å‡ºçµæœï¼ˆå¯é¸ï¼‰
   â””â”€ Excel / CSV / JSON
